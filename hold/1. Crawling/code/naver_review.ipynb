{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준편차 차이가 큰 상위 5개는 인천상륙작전, 형, 내안의 그놈, 연평해전, 공조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd57d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "movie_codes = [142822,142803,164172,102272,142384]\n",
    "movie_nums = [38,51,149,9,63]\n",
    "\n",
    "review_list=[]\n",
    "# 영화 id 수만큼 id 반복\n",
    "for movie_code, movie_num in zip(movie_codes, movie_nums):\n",
    "    url_1 = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code='+str(movie_code)\n",
    "    url_2 = '&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&onlyActualPointYn=Y&page='\n",
    "    url_m = 'https://movie.naver.com/movie/bi/mi/basic.naver?code=' + str(movie_code)\n",
    "    num = 0 \n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('—headless')\n",
    "    chrome_options.add_argument('—no-sandbox')\n",
    "    chrome_options.add_argument('—disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url_m)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    movie_name = soup.select(\"div.mv_info_area > div.mv_info > h3 > a\")[0].text\n",
    "    \n",
    "    # 1부터 10페이지까지 돌림\n",
    "    for page in range(1,11):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"headless\")\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        url = url_1+url_2+f'{page}'\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        \n",
    "        # 각 페이지 별 review (각 페이지당 댓글 10개)\n",
    "        for i in range(10):\n",
    "            review = soup.find('span',{'id':f'_filtered_ment_{i}'})\n",
    "            review = review.get_text().strip()\n",
    "            score = soup.select(\"div.star_score > em\")[i].text.strip()\n",
    "            \n",
    "            num += 1\n",
    "            \n",
    "            review_list.append([movie_num, num, movie_name,int(score)/2, review])\n",
    "            \n",
    "df = pd.DataFrame(review_list, columns=[\"순번\", \"순서\", \"영화이름\", \"관람객평점\",\"댓글\"])\n",
    "df.index = df.index+1\n",
    "print(df)\n",
    "df\n",
    "\n",
    "# df.to_csv(\"naver_review.csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015년도 흥행작 top30 네이버 영화 코드 입력 + 영화이름 추가\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "movie_codes = [115977,121048,98438]\n",
    "\n",
    "review_list=[]\n",
    "# 영화 id 수만큼 id 반복\n",
    "for movie_code in movie_codes:\n",
    "    url_1 = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code='+str(movie_code)\n",
    "    url_2 = '&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&onlyActualPointYn=Y&page='\n",
    "    url_m = 'https://movie.naver.com/movie/bi/mi/basic.naver?code=' + str(movie_code)\n",
    "    num = 0 \n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('—headless')\n",
    "    chrome_options.add_argument('—no-sandbox')\n",
    "    chrome_options.add_argument('—disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome('chromedriver.exe', options=chrome_options)\n",
    "    driver.get(url_m)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    movie_name = soup.select(\"div.mv_info_area > div.mv_info > h3 > a\")[0].text\n",
    "    \n",
    "    # 1부터 10페이지까지 돌림\n",
    "    for page in range(1,2):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"headless\")\n",
    "        driver = webdriver.Chrome('chromedriver.exe', options=chrome_options)\n",
    "        url = url_1+url_2+f'{page}'\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        \n",
    "        # 각 페이지 별 review (각 페이지당 댓글 10개)\n",
    "        for i in range(10):\n",
    "            review = soup.find('span',{'id':f'_filtered_ment_{i}'})\n",
    "            review = review.get_text().strip()\n",
    "            score = soup.select(\"div.star_score > em\")[i].text.strip()\n",
    "            \n",
    "            num += 1\n",
    "            \n",
    "            review_list.append([num, movie_code,movie_name,int(score)/2, review])\n",
    "\n",
    "            \n",
    "            \n",
    "df = pd.DataFrame(review_list, columns=[\"num\",\"영화코드\",\"영화이름\",\"평점\",\"댓글\"])\n",
    "df.index = df.index+1\n",
    "# print(df)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
